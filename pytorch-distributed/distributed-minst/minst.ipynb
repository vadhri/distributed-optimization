{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa031725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shard 1 (digits 0-4): 30596 samples saved to mnist_shards/mnist_0_4.npz\n",
      "Shard 2 (digits 5-9): 29404 samples saved to mnist_shards/mnist_5_9.npz\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Download MNIST dataset\n",
    "transform = transforms.ToTensor()\n",
    "mnist = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "# Split into two shards: 0-4 and 5-9\n",
    "data = mnist.data.numpy()\n",
    "targets = mnist.targets.numpy()\n",
    "\n",
    "shard1_idx = np.isin(targets, [0,1,2,3,4])\n",
    "shard2_idx = np.isin(targets, [5,6,7,8,9])\n",
    "\n",
    "shard1_data = data[shard1_idx]\n",
    "shard1_targets = targets[shard1_idx]\n",
    "shard2_data = data[shard2_idx]\n",
    "shard2_targets = targets[shard2_idx]\n",
    "\n",
    "os.makedirs('mnist_shards', exist_ok=True)\n",
    "np.savez_compressed('mnist_shards/mnist_0_4.npz', data=shard1_data, targets=shard1_targets)\n",
    "np.savez_compressed('mnist_shards/mnist_5_9.npz', data=shard2_data, targets=shard2_targets)\n",
    "\n",
    "print(f\"Shard 1 (digits 0-4): {shard1_data.shape[0]} samples saved to mnist_shards/mnist_0_4.npz\")\n",
    "print(f\"Shard 2 (digits 5-9): {shard2_data.shape[0]} samples saved to mnist_shards/mnist_5_9.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "819d0595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Digit 0: 5923 samples saved to mnist_shards/mnist_0.npz\n",
      "Digit 1: 6742 samples saved to mnist_shards/mnist_1.npz\n",
      "Digit 2: 5958 samples saved to mnist_shards/mnist_2.npz\n",
      "Digit 3: 6131 samples saved to mnist_shards/mnist_3.npz\n",
      "Digit 4: 5842 samples saved to mnist_shards/mnist_4.npz\n",
      "Digit 5: 5421 samples saved to mnist_shards/mnist_5.npz\n",
      "Digit 6: 5918 samples saved to mnist_shards/mnist_6.npz\n",
      "Digit 7: 6265 samples saved to mnist_shards/mnist_7.npz\n",
      "Digit 8: 5851 samples saved to mnist_shards/mnist_8.npz\n",
      "Digit 9: 5949 samples saved to mnist_shards/mnist_9.npz\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Download MNIST dataset if not already present\n",
    "transform = transforms.ToTensor()\n",
    "mnist = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "data = mnist.data.numpy()\n",
    "targets = mnist.targets.numpy()\n",
    "\n",
    "os.makedirs('mnist_shards', exist_ok=True)\n",
    "for digit in range(10):\n",
    "    idx = (targets == digit)\n",
    "    digit_data = data[idx]\n",
    "    digit_targets = targets[idx]\n",
    "    np.savez_compressed(f'mnist_shards/mnist_{digit}.npz', data=digit_data, targets=digit_targets)\n",
    "    print(f\"Digit {digit}: {digit_data.shape[0]} samples saved to mnist_shards/mnist_{digit}.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b39fdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "class MNISTResNet18(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = models.resnet18(weights=None)\n",
    "        self.model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.model.fc = nn.Linear(self.model.fc.in_features, 10)\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca30e384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting train_ddp_mnist.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile train_ddp_mnist.py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.multiprocessing as mp\n",
    "import torch.distributed as dist\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import torchvision.models as models\n",
    "\n",
    "class MNISTResNet18(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = models.resnet18(weights=None)\n",
    "        self.model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.model.fc = nn.Linear(self.model.fc.in_features, 10)\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "def load_shard(rank):\n",
    "    shard_file = f\"mnist_shards/mnist_0_4.npz\" if rank == 0 else f\"mnist_shards/mnist_5_9.npz\"\n",
    "    data = np.load(shard_file)\n",
    "    X = torch.tensor(data['data'], dtype=torch.float32).unsqueeze(1) / 255.0\n",
    "    y = torch.tensor(data['targets'], dtype=torch.long)\n",
    "    return TensorDataset(X, y)\n",
    "\n",
    "def train(rank, world_size):\n",
    "    print ('training on ', rank)\n",
    "    dist.init_process_group('gloo', rank=rank, world_size=world_size)\n",
    "    dataset = load_shard(rank)\n",
    "    loader = DataLoader(dataset, batch_size=128, shuffle=True)\n",
    "    model = MNISTResNet18()\n",
    "    model = nn.parallel.DistributedDataParallel(model)\n",
    "    device = torch.device('cpu')\n",
    "    model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    for epoch in range(3):\n",
    "        for X, y in loader:\n",
    "            optimizer.zero_grad()\n",
    "            out = model(X)\n",
    "            loss = criterion(out, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        if rank == 0:\n",
    "            print(f\"Epoch {epoch+1} complete. Loss: {loss.item():.4f}\")\n",
    "    dist.destroy_process_group()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    world_size = 2\n",
    "    mp.spawn(train, args=(world_size,), nprocs=world_size, join=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2f859a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting train_ddp_mnist.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile train_ddp_mnist.py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.multiprocessing as mp\n",
    "import torch.distributed as dist\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import torchvision.models as models\n",
    "import os\n",
    "\n",
    "os.environ['MASTER_ADDR'] = '127.0.0.1'\n",
    "os.environ['MASTER_PORT'] = '12355'\n",
    "\n",
    "class MNISTResNet18(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = models.resnet18(weights=None)\n",
    "        self.model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.model.fc = nn.Linear(self.model.fc.in_features, 10)\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "def load_digit_shard(digit):\n",
    "    # Each process loads only its digit's data from its own shard file\n",
    "    data = np.load(f'mnist_shards/mnist_{digit}.npz')\n",
    "    X = torch.tensor(data['data'], dtype=torch.float32).unsqueeze(1) / 255.0\n",
    "    y = torch.tensor(data['targets'], dtype=torch.long)\n",
    "    return TensorDataset(X, y)\n",
    "\n",
    "def train(rank, world_size):\n",
    "    dist.init_process_group('gloo', rank=rank, world_size=world_size)\n",
    "    print(f'Train on {rank} cpu')\n",
    "    dataset = load_digit_shard(rank)\n",
    "    loader = DataLoader(dataset, batch_size=128, shuffle=True)\n",
    "    model = MNISTResNet18()\n",
    "    model = nn.parallel.DistributedDataParallel(model)\n",
    "    device = torch.device('cpu')\n",
    "    model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    for epoch in range(3):\n",
    "        loadercnt = 0\n",
    "        for X, y in loader:\n",
    "            optimizer.zero_grad()\n",
    "            out = model(X)\n",
    "            loss = criterion(out, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loadercnt += 1\n",
    "            if loadercnt > 10:\n",
    "                break\n",
    "        if rank == 0:\n",
    "            print(f\"Digit {rank} Epoch {epoch+1} complete. Loss: {loss.item():.4f}\")\n",
    "    dist.destroy_process_group()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    world_size = 10\n",
    "    mp.spawn(train, args=(world_size,), nprocs=world_size, join=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a343a783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 0 cpu\n",
      "Train on 1 cpu\n",
      "Train on 2 cpu\n",
      "Train on 4 cpu\n",
      "Train on 5 cpu\n",
      "Train on 6 cpu\n",
      "Train on 8 cpu\n",
      "Train on 9 cpu\n",
      "Train on 7 cpu\n",
      "Train on 3 cpu\n",
      "Digit 0 Epoch 1 complete. Loss: 0.8005\n",
      "Digit 0 Epoch 2 complete. Loss: 0.1087\n",
      "Digit 0 Epoch 3 complete. Loss: 0.0248\n"
     ]
    }
   ],
   "source": [
    "!MASTER_ADDR=127.0.0.1 MASTER_PORT=12355 python3 train_ddp_mnist.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e0b8ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
