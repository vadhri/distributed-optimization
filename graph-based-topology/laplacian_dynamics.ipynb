{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOdQ6CtcLwVkrdVQrDuCgFy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vadhri/distibuted-optimization/blob/main/graph-based-topology/laplacian_dynamics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q igraph"
      ],
      "metadata": {
        "id": "SZg2J4gtb0z8"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwO8DOvEbotq",
        "outputId": "9173c01f-72c7-48e3-b1f2-5c589033008d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " avg =  0.0\n"
          ]
        }
      ],
      "source": [
        "import igraph as ig\n",
        "import numpy as np\n",
        "\n",
        "N = 1000\n",
        "\n",
        "# construct a full graph\n",
        "g=ig.Graph.Full(N)\n",
        "\n",
        "A = g.get_adjacency()\n",
        "# construct diagonal matrrix from degree\n",
        "D = np.diag(g.degree())\n",
        "\n",
        "# construct Laplacian\n",
        "L = D - A\n",
        "\n",
        "x = [10,]*N\n",
        "b = np.dot(L,x)\n",
        "print(' avg = ', np.average(b))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.random.uniform(0,1000,N)\n",
        "#compute median and avg of x\n",
        "alpha = (1/N)\n",
        "print ('median = ', np.median(x), 'avg = ', np.average(x))\n",
        "for iter in range(100):\n",
        "  x = x - (alpha * L @ x)\n",
        "  # check if values of x are in tol limits to each otherr\n",
        "  tol = x[0]\n",
        "  conv = np.all([np.isclose(tol, i) for i in x])\n",
        "  if conv == True:\n",
        "    print ('converged at iter = ', iter)\n",
        "    print (x)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IcS2EWsocPac",
        "outputId": "d324e399-77ae-46a9-9e6d-5d55a06a759f"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "median =  523.0414856775477 avg =  505.4024123250997\n",
            "converged at iter =  0\n",
            "[505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233\n",
            " 505.40241233 505.40241233 505.40241233 505.40241233 505.40241233]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile laplacian.c\n",
        "#include <igraph.h>\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <math.h>\n",
        "\n",
        "#define N 10000\n",
        "#define MAX_ITER 100\n",
        "#define TOL 1e-4\n",
        "#define ALPHA (1/N)\n",
        "\n",
        "int main() {\n",
        "    igraph_t g;\n",
        "    igraph_matrix_t A, L;\n",
        "    igraph_real_t *x = calloc(N, sizeof(igraph_real_t));\n",
        "    igraph_real_t *x_next = calloc(N, sizeof(igraph_real_t));\n",
        "\n",
        "    // Create a fully connected undirected graph\n",
        "    igraph_full(&g, N, IGRAPH_UNDIRECTED, IGRAPH_NO_LOOPS);\n",
        "\n",
        "    // Initialize x with random values between 100 and 500\n",
        "    for (int i = 0; i < N; ++i)\n",
        "        x[i] = (rand() % 400) + 100;\n",
        "\n",
        "    // Calculate initial average\n",
        "    igraph_real_t avg = 0.0;\n",
        "    for (int i = 0; i < N; ++i)\n",
        "        avg += x[i];\n",
        "    avg /= N;\n",
        "    printf(\"Average of x: %.4f\\n\", avg);\n",
        "\n",
        "    // Compute adjacency matrix A\n",
        "    igraph_matrix_init(&A, N, N);\n",
        "    igraph_get_adjacency(&g, &A, IGRAPH_GET_ADJACENCY_BOTH, /*loops=*/0);\n",
        "\n",
        "    // Compute Laplacian L = D - A\n",
        "    igraph_matrix_init(&L, N, N);\n",
        "    for (int i = 0; i < N; ++i) {\n",
        "        igraph_real_t degree = 0.0;\n",
        "        for (int j = 0; j < N; ++j) {\n",
        "            degree += MATRIX(A, i, j);\n",
        "        }\n",
        "        for (int j = 0; j < N; ++j) {\n",
        "            if (i == j)\n",
        "                MATRIX(L, i, j) = degree;\n",
        "            else\n",
        "                MATRIX(L, i, j) = -MATRIX(A, i, j);\n",
        "        }\n",
        "    }\n",
        "\n",
        "    // Apply Laplacian dynamics\n",
        "    int iter = 0;\n",
        "    igraph_real_t diff = INFINITY;\n",
        "\n",
        "    while (iter < MAX_ITER && diff > TOL) {\n",
        "        diff = 0.0;\n",
        "\n",
        "        for (int i = 0; i < N; ++i) {\n",
        "            igraph_real_t lap = 0.0;\n",
        "            for (int j = 0; j < N; ++j) {\n",
        "                lap += MATRIX(L, i, j) * x[j];\n",
        "            }\n",
        "            x_next[i] = x[i] - ALPHA * lap;\n",
        "            diff += fabs(x_next[i] - x[i]);\n",
        "        }\n",
        "\n",
        "        // Swap x and x_next\n",
        "        igraph_real_t *temp = x;\n",
        "        x = x_next;\n",
        "        x_next = temp;\n",
        "\n",
        "        if (iter % 10 == 0)\n",
        "            printf(\"Iteration %d, diff = %.6f\\n\", iter, diff / N);\n",
        "\n",
        "        ++iter;\n",
        "    }\n",
        "\n",
        "    // Print first 10 values\n",
        "    for (int i = 0; i < 10; ++i)\n",
        "        printf(\"%.4f \", x[i]);\n",
        "    printf(\"\\n\");\n",
        "\n",
        "    printf(\"Converged in %d iterations. Consensus value: %.4f\\n\", iter, x[0]);\n",
        "\n",
        "    // Cleanup\n",
        "    igraph_matrix_destroy(&A);\n",
        "    igraph_matrix_destroy(&L);\n",
        "    igraph_destroy(&g);\n",
        "    free(x);\n",
        "    free(x_next);\n",
        "\n",
        "    return 0;\n",
        "}\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZxxJYHmf_eP",
        "outputId": "6ae218bf-bc3d-4b98-8a26-7190a86eef1d"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting laplacian.c\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /usr/include/igraph/igraph.h\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4FObTaLckxMV",
        "outputId": "77ab2664-5a96-4bf1-c668-8c7dfad348e6"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/include/igraph/igraph.h\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "apt-get update\n",
        "apt-get install -y libigraph-dev\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUymOfiHkTF2",
        "outputId": "5f488679-51e9-43e3-901f-483408d239d8"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:3 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:4 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists...\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "libigraph-dev is already the newest version (0.9.6+ds-2ubuntu1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 36 not upgraded.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gcc laplacian.c -I/usr/include/igraph -L/usr/lib/x86_64-linux-gnu -ligraph -lm -o laplacian\n",
        "!time ./laplacian"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XpH3Z1x2jr4R",
        "outputId": "e25e1ba2-f1b9-4082-96e2-99f387fde909"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average of x: 298.4811\n",
            "Iteration 0, diff = 0.000000\n",
            "283.0000 186.0000 477.0000 215.0000 293.0000 435.0000 286.0000 192.0000 349.0000 321.0000 \n",
            "Converged in 1 iterations. Consensus value: 283.0000\n",
            "\n",
            "real\t0m30.383s\n",
            "user\t0m27.759s\n",
            "sys\t0m2.480s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile laplacian_cuda.cu\n",
        "#include <igraph.h>\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <math.h>\n",
        "\n",
        "#define N 15000         // Adjust to 10000 if your GPU has enough memory\n",
        "#define MAX_ITER 1000\n",
        "#define TOL 1e-3\n",
        "#define ALPHA 0.0001\n",
        "\n",
        "// CUDA kernel for Laplacian update: x_next = x - α * Lx\n",
        "__global__ void laplacian_update(double* x, double* x_next, double* L, int n, double alpha) {\n",
        "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (i < n) {\n",
        "        double Lx_i = 0.0;\n",
        "        for (int j = 0; j < n; ++j) {\n",
        "            Lx_i += L[i * n + j] * x[j];\n",
        "        }\n",
        "        x_next[i] = x[i] - alpha * Lx_i;\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    igraph_t g;\n",
        "    igraph_matrix_t adj;\n",
        "    igraph_matrix_init(&adj, 0, 0);\n",
        "    igraph_full(&g, N, IGRAPH_UNDIRECTED, IGRAPH_NO_LOOPS);\n",
        "    igraph_get_adjacency(&g, &adj, IGRAPH_GET_ADJACENCY_BOTH, /*loops=*/0);\n",
        "\n",
        "    // Compute degree matrix D\n",
        "    igraph_vector_t degrees;\n",
        "    igraph_vector_init(&degrees, 0);\n",
        "    igraph_degree(&g, &degrees, igraph_vss_all(), IGRAPH_ALL, IGRAPH_NO_LOOPS);\n",
        "\n",
        "    // Build Laplacian matrix L = D - A\n",
        "    double* L = (double*)malloc(N * N * sizeof(double));\n",
        "    for (int i = 0; i < N; ++i) {\n",
        "        for (int j = 0; j < N; ++j) {\n",
        "            if (i == j) {\n",
        "                L[i * N + j] = VECTOR(degrees)[i];\n",
        "            } else {\n",
        "                L[i * N + j] = -MATRIX(adj, i, j);\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "\n",
        "    // Initialize x with random values\n",
        "    double* x_host = (double*)malloc(N * sizeof(double));\n",
        "    double* x_next_host = (double*)malloc(N * sizeof(double));\n",
        "    for (int i = 0; i < N; ++i)\n",
        "        x_host[i] = (rand() % 400) + 100;\n",
        "\n",
        "    // compute avg of x_host values\n",
        "    double avg = 0.0;\n",
        "    for (int i = 0; i < N; ++i)\n",
        "        avg += x_host[i];\n",
        "    avg /= N;\n",
        "    printf(\"Average of x: %.4f\\n\", avg);\n",
        "\n",
        "    // CUDA device memory\n",
        "    double *x_dev, *x_next_dev, *L_dev;\n",
        "    cudaMalloc(&x_dev, N * sizeof(double));\n",
        "    cudaMalloc(&x_next_dev, N * sizeof(double));\n",
        "    cudaMalloc(&L_dev, N * N * sizeof(double));\n",
        "\n",
        "    // Copy data to device\n",
        "    cudaMemcpy(x_dev, x_host, N * sizeof(double), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(L_dev, L, N * N * sizeof(double), cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Kernel launch configuration\n",
        "    int threadsPerBlock = 256;\n",
        "    int blocksPerGrid = (N + threadsPerBlock - 1) / threadsPerBlock;\n",
        "\n",
        "    // Consensus iteration loop\n",
        "    int iter = 0;\n",
        "    double diff = INFINITY;\n",
        "    while (iter < MAX_ITER && diff > TOL) {\n",
        "        laplacian_update<<<blocksPerGrid, threadsPerBlock>>>(x_dev, x_next_dev, L_dev, N, ALPHA);\n",
        "        cudaDeviceSynchronize();\n",
        "\n",
        "        // Copy back and compute diff\n",
        "        cudaMemcpy(x_next_host, x_next_dev, N * sizeof(double), cudaMemcpyDeviceToHost);\n",
        "        diff = 0.0;\n",
        "        for (int i = 0; i < N; ++i)\n",
        "            diff += fabs(x_next_host[i] - x_host[i]);\n",
        "\n",
        "        // Swap pointers\n",
        "        double* tmp = x_host;\n",
        "        x_host = x_next_host;\n",
        "        x_next_host = tmp;\n",
        "        cudaMemcpy(x_dev, x_host, N * sizeof(double), cudaMemcpyHostToDevice);\n",
        "\n",
        "        if (iter % 10 == 0)\n",
        "            printf(\"Iter %d: avg diff = %.6f\\n\", iter, diff / N);\n",
        "        iter++;\n",
        "    }\n",
        "\n",
        "    // Final output\n",
        "    printf(\"Converged in %d iterations. First 10 values of x:\\n\", iter);\n",
        "    for (int i = 0; i < 10; ++i)\n",
        "        printf(\"%.4f \", x_host[i]);\n",
        "    printf(\"\\n\");\n",
        "\n",
        "    // prinnt any cuda errorrs\n",
        "    cudaError_t cudaErr = cudaGetLastError();\n",
        "    if (cudaErr != cudaSuccess) {\n",
        "        printf(\"CUDA error: %s\\n\", cudaGetErrorString(cudaErr));\n",
        "    }\n",
        "\n",
        "    // Free\n",
        "    igraph_destroy(&g);\n",
        "    igraph_vector_destroy(&degrees);\n",
        "    igraph_matrix_destroy(&adj);\n",
        "    cudaFree(x_dev);\n",
        "    cudaFree(x_next_dev);\n",
        "    cudaFree(L_dev);\n",
        "    free(x_host);\n",
        "    free(x_next_host);\n",
        "    free(L);\n",
        "    return 0;\n",
        "}\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dw9fMJnrkFmJ",
        "outputId": "0e56d894-f38c-4acc-a447-ff19b8b6a59f"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting laplacian_cuda.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc laplacian_cuda.cu -ligraph -o laplacian_cuda -I/usr/include/igraph -L/usr/lib/x86_64-linux-gnu -ligraph -lm -gencode arch=compute_75,code=sm_75\n",
        "!time ./laplacian_cuda\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQaO6uDopSK_",
        "outputId": "a61c68e3-27d6-49c5-af6a-73eb5d2841ee"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average of x: 298.9270\n",
            "Iter 0: avg diff = 150.782169\n",
            "Iter 10: avg diff = 0.147248\n",
            "Iter 20: avg diff = 0.000144\n",
            "Iter 30: avg diff = 0.000000\n",
            "Converged in 33 iterations. First 10 values of x:\n",
            "298.9270 298.9270 298.9270 298.9270 298.9270 298.9270 298.9270 298.9270 298.9270 298.9270 \n",
            "\n",
            "real\t0m53.902s\n",
            "user\t0m47.864s\n",
            "sys\t0m5.415s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Qma6dXj7prIj"
      },
      "execution_count": 109,
      "outputs": []
    }
  ]
}